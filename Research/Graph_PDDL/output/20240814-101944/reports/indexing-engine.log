10:19:44,754 graphrag.config.read_dotenv INFO Loading pipeline .env file
10:19:44,757 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 56",
        "type": "openai_chat",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./Graph_PDDL",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": true,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": true,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
10:19:44,758 graphrag.index.create_pipeline_config INFO skipping workflows 
10:19:45,370 graphrag.index.run INFO Running pipeline
10:19:45,370 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at Graph_PDDL/output/20240814-101944/artifacts
10:19:45,371 graphrag.index.input.load_input INFO loading input from root_dir=input
10:19:45,371 graphrag.index.input.load_input INFO using file storage for input
10:19:45,372 graphrag.index.storage.file_pipeline_storage INFO search Graph_PDDL/input for files matching .*\.txt$
10:19:45,372 graphrag.index.input.text INFO found text files from input, found [('GraphPDDL.txt', {})]
10:19:45,374 graphrag.index.input.text INFO Found 1 files, loading 1
10:19:45,377 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
10:19:45,377 graphrag.index.run INFO Final # of rows loaded: 1
10:19:45,481 graphrag.index.run INFO Running workflow: create_base_text_units...
10:19:45,481 graphrag.index.run INFO dependencies for create_base_text_units: []
10:19:45,483 datashaper.workflow.workflow INFO executing verb orderby
10:19:45,487 datashaper.workflow.workflow INFO executing verb zip
10:19:45,489 datashaper.workflow.workflow INFO executing verb aggregate_override
10:19:45,493 datashaper.workflow.workflow INFO executing verb chunk
10:19:48,73 datashaper.workflow.workflow INFO executing verb select
10:19:48,77 datashaper.workflow.workflow INFO executing verb unroll
10:19:48,83 datashaper.workflow.workflow INFO executing verb rename
10:19:48,85 datashaper.workflow.workflow INFO executing verb genid
10:19:48,88 datashaper.workflow.workflow INFO executing verb unzip
10:19:48,92 datashaper.workflow.workflow INFO executing verb copy
10:19:48,94 datashaper.workflow.workflow INFO executing verb filter
10:19:48,102 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
10:19:48,273 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
10:19:48,273 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
10:19:48,273 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
10:19:48,301 datashaper.workflow.workflow INFO executing verb entity_extract
10:19:48,303 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
10:19:48,311 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o-mini: TPM=0, RPM=0
10:19:48,311 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o-mini: 25
10:19:51,946 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:51,952 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.6049999999813735. input_tokens=2008, output_tokens=318
10:19:52,416 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:52,419 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.091999999945983. input_tokens=2936, output_tokens=370
10:19:52,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:52,952 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.608000000007451. input_tokens=2935, output_tokens=380
10:19:53,326 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:53,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.9910000001545995. input_tokens=2936, output_tokens=501
10:19:53,447 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:53,449 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.112999999895692. input_tokens=2935, output_tokens=498
10:19:53,917 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:53,919 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.596999999834225. input_tokens=2936, output_tokens=485
10:19:54,6 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:54,10 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.6859999999869615. input_tokens=2936, output_tokens=526
10:19:54,112 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:54,115 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.781999999890104. input_tokens=2935, output_tokens=420
10:19:54,637 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:54,641 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.310000000055879. input_tokens=2937, output_tokens=482
10:19:54,644 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:54,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.304000000003725. input_tokens=2936, output_tokens=594
10:19:54,699 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:54,701 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.385000000009313. input_tokens=2936, output_tokens=477
10:19:55,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:55,567 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 3.6119999999646097. input_tokens=34, output_tokens=272
10:19:55,622 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:55,623 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.294999999925494. input_tokens=2936, output_tokens=421
10:19:57,271 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:57,274 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 3.941999999806285. input_tokens=34, output_tokens=405
10:19:57,639 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:57,642 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.191000000108033. input_tokens=34, output_tokens=460
10:19:58,415 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:58,419 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 5.466000000014901. input_tokens=34, output_tokens=377
10:19:58,713 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:58,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.79300000006333. input_tokens=34, output_tokens=412
10:19:59,378 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:59,383 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.727999999886379. input_tokens=34, output_tokens=394
10:19:59,686 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:19:59,689 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.986000000033528. input_tokens=34, output_tokens=430
10:20:00,34 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:00,37 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 5.920000000158325. input_tokens=34, output_tokens=496
10:20:00,264 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:00,268 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 7.843000000109896. input_tokens=34, output_tokens=554
10:20:00,732 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:00,737 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.090000000083819. input_tokens=34, output_tokens=436
10:20:01,191 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:01,198 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 7.185000000055879. input_tokens=34, output_tokens=639
10:20:01,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:01,803 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.178000000072643. input_tokens=34, output_tokens=548
10:20:06,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:06,575 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 18.23200000007637. input_tokens=2937, output_tokens=1395
10:20:13,38 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:13,42 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.462999999988824. input_tokens=34, output_tokens=600
10:20:13,68 datashaper.workflow.workflow INFO executing verb merge_graphs
10:20:13,103 datashaper.workflow.workflow INFO executing verb snapshot_rows
10:20:13,107 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
10:20:13,279 graphrag.index.run INFO Running workflow: create_summarized_entities...
10:20:13,279 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
10:20:13,280 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
10:20:13,308 datashaper.workflow.workflow INFO executing verb summarize_descriptions
10:20:14,75 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,77 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7430000000167638. input_tokens=161, output_tokens=41
10:20:14,298 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,300 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9640000001527369. input_tokens=177, output_tokens=64
10:20:14,393 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,395 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0390000001061708. input_tokens=177, output_tokens=72
10:20:14,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0719999999273568. input_tokens=169, output_tokens=58
10:20:14,433 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,434 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1019999999552965. input_tokens=165, output_tokens=46
10:20:14,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,489 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1430000001564622. input_tokens=175, output_tokens=67
10:20:14,587 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,588 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2269999999552965. input_tokens=170, output_tokens=51
10:20:14,602 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.246999999973923. input_tokens=160, output_tokens=75
10:20:14,608 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,609 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.256000000052154. input_tokens=183, output_tokens=75
10:20:14,641 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,643 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3029999998398125. input_tokens=185, output_tokens=57
10:20:14,652 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,653 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2989999998826534. input_tokens=158, output_tokens=52
10:20:14,679 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,681 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.340000000083819. input_tokens=183, output_tokens=79
10:20:14,707 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,709 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3600000001024455. input_tokens=214, output_tokens=77
10:20:14,724 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,726 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3870000001043081. input_tokens=230, output_tokens=86
10:20:14,740 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,742 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3900000001303852. input_tokens=158, output_tokens=82
10:20:14,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,753 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4080000000540167. input_tokens=204, output_tokens=112
10:20:14,754 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,756 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4140000001061708. input_tokens=167, output_tokens=59
10:20:14,789 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4429999999701977. input_tokens=167, output_tokens=80
10:20:14,813 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,814 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.456000000005588. input_tokens=177, output_tokens=71
10:20:14,898 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,900 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.569999999832362. input_tokens=304, output_tokens=101
10:20:14,942 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,948 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6040000000502914. input_tokens=168, output_tokens=72
10:20:14,949 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:14,951 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5929999998770654. input_tokens=180, output_tokens=67
10:20:15,28 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:15,31 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.668999999994412. input_tokens=257, output_tokens=139
10:20:15,171 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:15,180 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8469999998342246. input_tokens=190, output_tokens=117
10:20:15,209 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:15,213 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1350000000093132. input_tokens=175, output_tokens=68
10:20:15,712 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:15,716 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.415000000037253. input_tokens=166, output_tokens=91
10:20:15,717 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:15,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2860000000800937. input_tokens=178, output_tokens=101
10:20:15,721 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:15,724 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3019999999087304. input_tokens=176, output_tokens=94
10:20:15,804 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:15,808 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4709999999031425. input_tokens=306, output_tokens=191
10:20:16,101 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:16,105 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.709999999962747. input_tokens=158, output_tokens=79
10:20:16,120 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:16,122 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6329999999143183. input_tokens=157, output_tokens=111
10:20:16,141 datashaper.workflow.workflow INFO executing verb snapshot_rows
10:20:16,146 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
10:20:16,263 graphrag.index.run INFO Running workflow: create_base_entity_graph...
10:20:16,263 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
10:20:16,263 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
10:20:16,271 datashaper.workflow.workflow INFO executing verb cluster_graph
10:20:16,312 datashaper.workflow.workflow INFO executing verb snapshot_rows
10:20:16,324 datashaper.workflow.workflow INFO executing verb embed_graph
10:20:16,332 root INFO Starting preprocessing of transition probabilities on graph with 47 nodes and 58 edges
10:20:16,332 root INFO Starting at time 1723602016.3329
10:20:16,332 root INFO Beginning preprocessing of transition probabilities for 47 vertices
10:20:16,332 root INFO Completed 1 / 47 vertices
10:20:16,332 root INFO Completed 5 / 47 vertices
10:20:16,333 root INFO Completed 9 / 47 vertices
10:20:16,333 root INFO Completed 13 / 47 vertices
10:20:16,333 root INFO Completed 17 / 47 vertices
10:20:16,333 root INFO Completed 21 / 47 vertices
10:20:16,333 root INFO Completed 25 / 47 vertices
10:20:16,333 root INFO Completed 29 / 47 vertices
10:20:16,333 root INFO Completed 33 / 47 vertices
10:20:16,333 root INFO Completed 37 / 47 vertices
10:20:16,333 root INFO Completed 41 / 47 vertices
10:20:16,333 root INFO Completed 45 / 47 vertices
10:20:16,333 root INFO Completed preprocessing of transition probabilities for vertices
10:20:16,333 root INFO Beginning preprocessing of transition probabilities for 58 edges
10:20:16,333 root INFO Completed 1 / 58 edges
10:20:16,333 root INFO Completed 6 / 58 edges
10:20:16,333 root INFO Completed 11 / 58 edges
10:20:16,333 root INFO Completed 16 / 58 edges
10:20:16,333 root INFO Completed 21 / 58 edges
10:20:16,334 root INFO Completed 26 / 58 edges
10:20:16,334 root INFO Completed 31 / 58 edges
10:20:16,334 root INFO Completed 36 / 58 edges
10:20:16,334 root INFO Completed 41 / 58 edges
10:20:16,334 root INFO Completed 46 / 58 edges
10:20:16,334 root INFO Completed 51 / 58 edges
10:20:16,334 root INFO Completed 56 / 58 edges
10:20:16,334 root INFO Completed preprocessing of transition probabilities for edges
10:20:16,334 root INFO Simulating walks on graph at time 1723602016.3344991
10:20:16,335 root INFO Walk iteration: 1/10
10:20:16,339 root INFO Walk iteration: 2/10
10:20:16,341 root INFO Walk iteration: 3/10
10:20:16,342 root INFO Walk iteration: 4/10
10:20:16,343 root INFO Walk iteration: 5/10
10:20:16,345 root INFO Walk iteration: 6/10
10:20:16,346 root INFO Walk iteration: 7/10
10:20:16,347 root INFO Walk iteration: 8/10
10:20:16,349 root INFO Walk iteration: 9/10
10:20:16,350 root INFO Walk iteration: 10/10
10:20:16,352 root INFO Learning embeddings at time 1723602016.352024
10:20:16,352 gensim.models.word2vec INFO collecting all words and their counts
10:20:16,352 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
10:20:16,353 gensim.models.word2vec INFO collected 47 word types from a corpus of 8520 raw words and 470 sentences
10:20:16,353 gensim.models.word2vec INFO Creating a fresh vocabulary
10:20:16,353 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 47 unique words (100.00% of original 47, drops 0)', 'datetime': '2024-08-14T10:20:16.353959', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,354 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 8520 word corpus (100.00% of original 8520, drops 0)', 'datetime': '2024-08-14T10:20:16.354014', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,354 gensim.models.word2vec INFO deleting the raw counts dictionary of 47 items
10:20:16,354 gensim.models.word2vec INFO sample=0.001 downsamples 47 most-common words
10:20:16,354 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2051.3280972895855 word corpus (24.1%% of prior 8520)', 'datetime': '2024-08-14T10:20:16.354389', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,354 gensim.models.word2vec INFO estimated required memory for 47 words and 1536 dimensions: 601036 bytes
10:20:16,354 gensim.models.word2vec INFO resetting layer weights
10:20:16,356 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-08-14T10:20:16.356009', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'build_vocab'}
10:20:16,356 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 47 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-08-14T10:20:16.356062', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}
10:20:16,374 gensim.models.word2vec INFO EPOCH 0: training on 8520 raw words (2091 effective words) took 0.0s, 118441 effective words/s
10:20:16,389 gensim.models.word2vec INFO EPOCH 1: training on 8520 raw words (2097 effective words) took 0.0s, 166277 effective words/s
10:20:16,402 gensim.models.word2vec INFO EPOCH 2: training on 8520 raw words (2025 effective words) took 0.0s, 167351 effective words/s
10:20:16,402 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 25560 raw words (6213 effective words) took 0.0s, 133357 effective words/s', 'datetime': '2024-08-14T10:20:16.402670', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}
10:20:16,402 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=47, vector_size=1536, alpha=0.025>', 'datetime': '2024-08-14T10:20:16.402708', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'created'}
10:20:16,402 root INFO Completed. Ending time is 1723602016.402743 Elapsed time is -0.06984305381774902
10:20:16,409 root INFO Starting preprocessing of transition probabilities on graph with 47 nodes and 58 edges
10:20:16,409 root INFO Starting at time 1723602016.4095712
10:20:16,409 root INFO Beginning preprocessing of transition probabilities for 47 vertices
10:20:16,409 root INFO Completed 1 / 47 vertices
10:20:16,409 root INFO Completed 5 / 47 vertices
10:20:16,409 root INFO Completed 9 / 47 vertices
10:20:16,409 root INFO Completed 13 / 47 vertices
10:20:16,409 root INFO Completed 17 / 47 vertices
10:20:16,409 root INFO Completed 21 / 47 vertices
10:20:16,409 root INFO Completed 25 / 47 vertices
10:20:16,409 root INFO Completed 29 / 47 vertices
10:20:16,409 root INFO Completed 33 / 47 vertices
10:20:16,409 root INFO Completed 37 / 47 vertices
10:20:16,409 root INFO Completed 41 / 47 vertices
10:20:16,409 root INFO Completed 45 / 47 vertices
10:20:16,409 root INFO Completed preprocessing of transition probabilities for vertices
10:20:16,409 root INFO Beginning preprocessing of transition probabilities for 58 edges
10:20:16,409 root INFO Completed 1 / 58 edges
10:20:16,410 root INFO Completed 6 / 58 edges
10:20:16,410 root INFO Completed 11 / 58 edges
10:20:16,410 root INFO Completed 16 / 58 edges
10:20:16,410 root INFO Completed 21 / 58 edges
10:20:16,410 root INFO Completed 26 / 58 edges
10:20:16,410 root INFO Completed 31 / 58 edges
10:20:16,410 root INFO Completed 36 / 58 edges
10:20:16,410 root INFO Completed 41 / 58 edges
10:20:16,410 root INFO Completed 46 / 58 edges
10:20:16,410 root INFO Completed 51 / 58 edges
10:20:16,410 root INFO Completed 56 / 58 edges
10:20:16,410 root INFO Completed preprocessing of transition probabilities for edges
10:20:16,410 root INFO Simulating walks on graph at time 1723602016.410856
10:20:16,410 root INFO Walk iteration: 1/10
10:20:16,412 root INFO Walk iteration: 2/10
10:20:16,413 root INFO Walk iteration: 3/10
10:20:16,414 root INFO Walk iteration: 4/10
10:20:16,416 root INFO Walk iteration: 5/10
10:20:16,417 root INFO Walk iteration: 6/10
10:20:16,418 root INFO Walk iteration: 7/10
10:20:16,419 root INFO Walk iteration: 8/10
10:20:16,420 root INFO Walk iteration: 9/10
10:20:16,422 root INFO Walk iteration: 10/10
10:20:16,423 root INFO Learning embeddings at time 1723602016.4232981
10:20:16,423 gensim.models.word2vec INFO collecting all words and their counts
10:20:16,423 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
10:20:16,424 gensim.models.word2vec INFO collected 47 word types from a corpus of 8520 raw words and 470 sentences
10:20:16,424 gensim.models.word2vec INFO Creating a fresh vocabulary
10:20:16,424 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 47 unique words (100.00% of original 47, drops 0)', 'datetime': '2024-08-14T10:20:16.424329', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,424 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 8520 word corpus (100.00% of original 8520, drops 0)', 'datetime': '2024-08-14T10:20:16.424367', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,424 gensim.models.word2vec INFO deleting the raw counts dictionary of 47 items
10:20:16,424 gensim.models.word2vec INFO sample=0.001 downsamples 47 most-common words
10:20:16,424 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2051.3280972895855 word corpus (24.1%% of prior 8520)', 'datetime': '2024-08-14T10:20:16.424505', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,424 gensim.models.word2vec INFO estimated required memory for 47 words and 1536 dimensions: 601036 bytes
10:20:16,424 gensim.models.word2vec INFO resetting layer weights
10:20:16,424 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-08-14T10:20:16.424930', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'build_vocab'}
10:20:16,424 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 47 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-08-14T10:20:16.424955', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}
10:20:16,440 gensim.models.word2vec INFO EPOCH 0: training on 8520 raw words (2091 effective words) took 0.0s, 151638 effective words/s
10:20:16,454 gensim.models.word2vec INFO EPOCH 1: training on 8520 raw words (2097 effective words) took 0.0s, 168602 effective words/s
10:20:16,467 gensim.models.word2vec INFO EPOCH 2: training on 8520 raw words (2025 effective words) took 0.0s, 167198 effective words/s
10:20:16,467 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 25560 raw words (6213 effective words) took 0.0s, 145933 effective words/s', 'datetime': '2024-08-14T10:20:16.467542', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}
10:20:16,467 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=47, vector_size=1536, alpha=0.025>', 'datetime': '2024-08-14T10:20:16.467580', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'created'}
10:20:16,467 root INFO Completed. Ending time is 1723602016.467616 Elapsed time is -0.0580449104309082
10:20:16,476 root INFO Starting preprocessing of transition probabilities on graph with 47 nodes and 58 edges
10:20:16,477 root INFO Starting at time 1723602016.477063
10:20:16,477 root INFO Beginning preprocessing of transition probabilities for 47 vertices
10:20:16,477 root INFO Completed 1 / 47 vertices
10:20:16,477 root INFO Completed 5 / 47 vertices
10:20:16,477 root INFO Completed 9 / 47 vertices
10:20:16,477 root INFO Completed 13 / 47 vertices
10:20:16,477 root INFO Completed 17 / 47 vertices
10:20:16,477 root INFO Completed 21 / 47 vertices
10:20:16,477 root INFO Completed 25 / 47 vertices
10:20:16,477 root INFO Completed 29 / 47 vertices
10:20:16,477 root INFO Completed 33 / 47 vertices
10:20:16,477 root INFO Completed 37 / 47 vertices
10:20:16,477 root INFO Completed 41 / 47 vertices
10:20:16,477 root INFO Completed 45 / 47 vertices
10:20:16,477 root INFO Completed preprocessing of transition probabilities for vertices
10:20:16,477 root INFO Beginning preprocessing of transition probabilities for 58 edges
10:20:16,477 root INFO Completed 1 / 58 edges
10:20:16,477 root INFO Completed 6 / 58 edges
10:20:16,477 root INFO Completed 11 / 58 edges
10:20:16,477 root INFO Completed 16 / 58 edges
10:20:16,478 root INFO Completed 21 / 58 edges
10:20:16,478 root INFO Completed 26 / 58 edges
10:20:16,478 root INFO Completed 31 / 58 edges
10:20:16,478 root INFO Completed 36 / 58 edges
10:20:16,478 root INFO Completed 41 / 58 edges
10:20:16,478 root INFO Completed 46 / 58 edges
10:20:16,478 root INFO Completed 51 / 58 edges
10:20:16,478 root INFO Completed 56 / 58 edges
10:20:16,478 root INFO Completed preprocessing of transition probabilities for edges
10:20:16,478 root INFO Simulating walks on graph at time 1723602016.478873
10:20:16,479 root INFO Walk iteration: 1/10
10:20:16,480 root INFO Walk iteration: 2/10
10:20:16,482 root INFO Walk iteration: 3/10
10:20:16,483 root INFO Walk iteration: 4/10
10:20:16,485 root INFO Walk iteration: 5/10
10:20:16,486 root INFO Walk iteration: 6/10
10:20:16,488 root INFO Walk iteration: 7/10
10:20:16,489 root INFO Walk iteration: 8/10
10:20:16,490 root INFO Walk iteration: 9/10
10:20:16,491 root INFO Walk iteration: 10/10
10:20:16,493 root INFO Learning embeddings at time 1723602016.493255
10:20:16,493 gensim.models.word2vec INFO collecting all words and their counts
10:20:16,493 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
10:20:16,494 gensim.models.word2vec INFO collected 47 word types from a corpus of 8520 raw words and 470 sentences
10:20:16,494 gensim.models.word2vec INFO Creating a fresh vocabulary
10:20:16,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 47 unique words (100.00% of original 47, drops 0)', 'datetime': '2024-08-14T10:20:16.494450', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 8520 word corpus (100.00% of original 8520, drops 0)', 'datetime': '2024-08-14T10:20:16.494485', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,494 gensim.models.word2vec INFO deleting the raw counts dictionary of 47 items
10:20:16,494 gensim.models.word2vec INFO sample=0.001 downsamples 47 most-common words
10:20:16,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2051.3280972895855 word corpus (24.1%% of prior 8520)', 'datetime': '2024-08-14T10:20:16.494636', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
10:20:16,494 gensim.models.word2vec INFO estimated required memory for 47 words and 1536 dimensions: 601036 bytes
10:20:16,494 gensim.models.word2vec INFO resetting layer weights
10:20:16,495 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-08-14T10:20:16.495175', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'build_vocab'}
10:20:16,495 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 47 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-08-14T10:20:16.495210', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}
10:20:16,510 gensim.models.word2vec INFO EPOCH 0: training on 8520 raw words (2091 effective words) took 0.0s, 156025 effective words/s
10:20:16,534 gensim.models.word2vec INFO EPOCH 1: training on 8520 raw words (2097 effective words) took 0.0s, 90584 effective words/s
10:20:16,551 gensim.models.word2vec INFO EPOCH 2: training on 8520 raw words (2025 effective words) took 0.0s, 130852 effective words/s
10:20:16,551 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 25560 raw words (6213 effective words) took 0.1s, 110097 effective words/s', 'datetime': '2024-08-14T10:20:16.551678', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}
10:20:16,551 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=47, vector_size=1536, alpha=0.025>', 'datetime': '2024-08-14T10:20:16.551738', 'gensim': '4.3.3', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'created'}
10:20:16,551 root INFO Completed. Ending time is 1723602016.551789 Elapsed time is -0.07472610473632812
10:20:16,556 datashaper.workflow.workflow INFO executing verb snapshot_rows
10:20:16,561 datashaper.workflow.workflow INFO executing verb select
10:20:16,566 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
10:20:16,724 graphrag.index.run INFO Running workflow: create_final_entities...
10:20:16,725 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
10:20:16,725 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:20:16,739 datashaper.workflow.workflow INFO executing verb unpack_graph
10:20:16,755 datashaper.workflow.workflow INFO executing verb rename
10:20:16,759 datashaper.workflow.workflow INFO executing verb select
10:20:16,764 datashaper.workflow.workflow INFO executing verb dedupe
10:20:16,769 datashaper.workflow.workflow INFO executing verb rename
10:20:16,774 datashaper.workflow.workflow INFO executing verb filter
10:20:16,785 datashaper.workflow.workflow INFO executing verb text_split
10:20:16,791 datashaper.workflow.workflow INFO executing verb drop
10:20:16,796 datashaper.workflow.workflow INFO executing verb merge
10:20:16,811 datashaper.workflow.workflow INFO executing verb text_embed
10:20:16,813 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
10:20:16,825 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
10:20:16,825 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
10:20:16,832 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 138 inputs via 138 snippets using 9 batches. max_batch_size=16, max_tokens=8191
10:20:17,309 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,313 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,341 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,356 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,358 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,364 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,365 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,422 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:20:17,757 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9189999999944121. input_tokens=294, output_tokens=0
10:20:17,884 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0479999999515712. input_tokens=558, output_tokens=0
10:20:17,915 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.081000000005588. input_tokens=830, output_tokens=0
10:20:17,937 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0979999999981374. input_tokens=462, output_tokens=0
10:20:17,952 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1170000000856817. input_tokens=698, output_tokens=0
10:20:17,965 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.128000000026077. input_tokens=411, output_tokens=0
10:20:17,977 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1419999999925494. input_tokens=652, output_tokens=0
10:20:17,989 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1520000000018626. input_tokens=428, output_tokens=0
10:20:18,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1670000001322478. input_tokens=551, output_tokens=0
10:20:18,31 datashaper.workflow.workflow INFO executing verb drop
10:20:18,36 datashaper.workflow.workflow INFO executing verb filter
10:20:18,44 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
10:20:18,176 graphrag.index.run INFO Running workflow: create_final_nodes...
10:20:18,176 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
10:20:18,176 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:20:18,192 datashaper.workflow.workflow INFO executing verb layout_graph
10:20:22,102 datashaper.workflow.workflow INFO executing verb unpack_graph
10:20:22,118 datashaper.workflow.workflow INFO executing verb unpack_graph
10:20:22,134 datashaper.workflow.workflow INFO executing verb filter
10:20:22,149 datashaper.workflow.workflow INFO executing verb drop
10:20:22,156 datashaper.workflow.workflow INFO executing verb select
10:20:22,162 datashaper.workflow.workflow INFO executing verb rename
10:20:22,168 datashaper.workflow.workflow INFO executing verb convert
10:20:22,195 datashaper.workflow.workflow INFO executing verb join
10:20:22,210 datashaper.workflow.workflow INFO executing verb rename
10:20:22,211 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
10:20:22,360 graphrag.index.run INFO Running workflow: create_final_communities...
10:20:22,360 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
10:20:22,360 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:20:22,378 datashaper.workflow.workflow INFO executing verb unpack_graph
10:20:22,395 datashaper.workflow.workflow INFO executing verb unpack_graph
10:20:22,412 datashaper.workflow.workflow INFO executing verb aggregate_override
10:20:22,422 datashaper.workflow.workflow INFO executing verb join
10:20:22,433 datashaper.workflow.workflow INFO executing verb join
10:20:22,444 datashaper.workflow.workflow INFO executing verb concat
10:20:22,452 datashaper.workflow.workflow INFO executing verb filter
10:20:22,521 datashaper.workflow.workflow INFO executing verb aggregate_override
10:20:22,533 datashaper.workflow.workflow INFO executing verb join
10:20:22,544 datashaper.workflow.workflow INFO executing verb filter
10:20:22,561 datashaper.workflow.workflow INFO executing verb fill
10:20:22,569 datashaper.workflow.workflow INFO executing verb merge
10:20:22,579 datashaper.workflow.workflow INFO executing verb copy
10:20:22,587 datashaper.workflow.workflow INFO executing verb select
10:20:22,589 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
10:20:22,709 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
10:20:22,709 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
10:20:22,709 graphrag.index.run INFO read table from storage: create_final_entities.parquet
10:20:22,735 datashaper.workflow.workflow INFO executing verb select
10:20:22,745 datashaper.workflow.workflow INFO executing verb unroll
10:20:22,755 datashaper.workflow.workflow INFO executing verb aggregate_override
10:20:22,757 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
10:20:22,873 graphrag.index.run INFO Running workflow: create_final_relationships...
10:20:22,876 graphrag.index.run INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
10:20:22,876 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
10:20:22,881 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:20:22,903 datashaper.workflow.workflow INFO executing verb unpack_graph
10:20:22,922 datashaper.workflow.workflow INFO executing verb filter
10:20:22,943 datashaper.workflow.workflow INFO executing verb rename
10:20:22,952 datashaper.workflow.workflow INFO executing verb filter
10:20:22,973 datashaper.workflow.workflow INFO executing verb drop
10:20:22,983 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
10:20:22,994 datashaper.workflow.workflow INFO executing verb convert
10:20:23,14 datashaper.workflow.workflow INFO executing verb convert
10:20:23,15 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
10:20:23,132 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
10:20:23,132 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
10:20:23,132 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
10:20:23,153 datashaper.workflow.workflow INFO executing verb select
10:20:23,163 datashaper.workflow.workflow INFO executing verb unroll
10:20:23,175 datashaper.workflow.workflow INFO executing verb aggregate_override
10:20:23,186 datashaper.workflow.workflow INFO executing verb select
10:20:23,187 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
10:20:23,302 graphrag.index.run INFO Running workflow: create_final_community_reports...
10:20:23,302 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
10:20:23,302 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
10:20:23,306 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
10:20:23,334 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
10:20:23,351 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
10:20:23,380 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
10:20:23,398 datashaper.workflow.workflow INFO executing verb prepare_community_reports
10:20:23,398 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 138
10:20:23,413 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 138
10:20:23,424 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 138
10:20:23,451 datashaper.workflow.workflow INFO executing verb create_community_reports
10:20:32,51 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:32,89 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.626999999862164. input_tokens=3046, output_tokens=797
10:20:35,49 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:35,54 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.591000000014901. input_tokens=2197, output_tokens=768
10:20:44,6 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:44,15 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.91800000006333. input_tokens=2756, output_tokens=723
10:20:44,186 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:44,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.083000000100583. input_tokens=2159, output_tokens=676
10:20:44,242 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:44,244 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.142999999923632. input_tokens=3198, output_tokens=829
10:20:49,792 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:49,796 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.5310000001918525. input_tokens=2067, output_tokens=556
10:20:49,986 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:49,989 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.7209999999031425. input_tokens=2113, output_tokens=433
10:20:50,733 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:50,736 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.459000000031665. input_tokens=2039, output_tokens=597
10:20:51,408 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:51,412 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.127000000094995. input_tokens=2944, output_tokens=734
10:20:51,575 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:51,578 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.317999999970198. input_tokens=2797, output_tokens=713
10:20:52,50 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:52,54 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.780999999959022. input_tokens=4011, output_tokens=823
10:20:52,187 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:52,190 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.909999999916181. input_tokens=2101, output_tokens=571
10:20:52,642 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:20:52,643 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.390000000130385. input_tokens=2296, output_tokens=685
10:20:52,677 datashaper.workflow.workflow INFO executing verb window
10:20:52,679 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
10:20:52,892 graphrag.index.run INFO Running workflow: create_final_text_units...
10:20:52,896 graphrag.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids', 'create_base_text_units']
10:20:52,896 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
10:20:52,898 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
10:20:52,900 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
10:20:52,923 datashaper.workflow.workflow INFO executing verb select
10:20:52,935 datashaper.workflow.workflow INFO executing verb rename
10:20:52,947 datashaper.workflow.workflow INFO executing verb join
10:20:52,961 datashaper.workflow.workflow INFO executing verb join
10:20:52,975 datashaper.workflow.workflow INFO executing verb aggregate_override
10:20:52,989 datashaper.workflow.workflow INFO executing verb select
10:20:52,992 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
10:20:53,115 graphrag.index.run INFO Running workflow: create_base_documents...
10:20:53,115 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
10:20:53,115 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
10:20:53,140 datashaper.workflow.workflow INFO executing verb unroll
10:20:53,153 datashaper.workflow.workflow INFO executing verb select
10:20:53,166 datashaper.workflow.workflow INFO executing verb rename
10:20:53,179 datashaper.workflow.workflow INFO executing verb join
10:20:53,193 datashaper.workflow.workflow INFO executing verb aggregate_override
10:20:53,207 datashaper.workflow.workflow INFO executing verb join
10:20:53,262 datashaper.workflow.workflow INFO executing verb rename
10:20:53,276 datashaper.workflow.workflow INFO executing verb convert
10:20:53,292 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
10:20:53,409 graphrag.index.run INFO Running workflow: create_final_documents...
10:20:53,409 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
10:20:53,409 graphrag.index.run INFO read table from storage: create_base_documents.parquet
10:20:53,438 datashaper.workflow.workflow INFO executing verb rename
10:20:53,439 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
